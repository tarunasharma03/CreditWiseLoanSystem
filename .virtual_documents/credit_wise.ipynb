import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


df = pd.read_csv("loan_approval_data.csv")


df.head()
df.info()





categorical_cols = df.select_dtypes(include=["object"]).columns
numerical_cols = df.select_dtypes(include=["number"]).columns


numerical_cols


from sklearn.impute import SimpleImputer

nump_imp = SimpleImputer(strategy="mean")
df[numerical_cols] = nump_imp.fit_transform(df[numerical_cols])


cat_imp = SimpleImputer(strategy="most_frequent")
df[categorical_cols] = cat_imp.fit_transform(df[categorical_cols])


df.head()








# how balanced our classes are?

classes_count = df["Loan_Approved"].value_counts()

plt.pie(classes_count,labels=["No","Yes"],autopct="%1.1f%%")
plt.title("Is Loan approved or not?")


# analyze categories
#gender_count = df["Gender"].value_counts()
#ax = sns.barplot(gender_count)
#ax.bar_label(ax.containers[0])

edu_count = df["Education_Level"].value_counts()
ax = sns.barplot(edu_count)
ax.bar_label(ax.containers[0])


# analyse applicant income

sns.histplot(
    data = df,
    x = "Applicant_Income",
    bins=20,
    
)


# analyse co-applicant income

sns.histplot(
    data = df,
    x = "Coapplicant_Income",
    bins=20,
    
)


# to check outliers in the dataset - box plot

sns.boxplot(
    data = df,
    x = "Loan_Approved",
    y = "Applicant_Income"
)


fig, axes = plt.subplots(2,2)

sns.boxplot(ax = axes[0,0],data = df,x = "Loan_Approved",y = "Applicant_Income")
sns.boxplot(ax = axes[0,1],data = df,x = "Loan_Approved",y = "Credit_Score")
sns.boxplot(ax = axes[1,0],data = df,x = "Loan_Approved",y = "DTI_Ratio")
sns.boxplot(ax = axes[1,1],data = df,x = "Loan_Approved",y = "Savings")

plt.tight_layout()


# Credit score with Loan amount
sns.histplot(
    data = df,
    x= "Credit_Score",
    hue= "Loan_Approved",
    bins= 20,
    multiple= "dodge"
)


# Remove Applicat Id
df = df.drop("Applicant_ID",axis=1)


df.head()
df.info()





from sklearn.preprocessing import LabelEncoder,OneHotEncoder

le = LabelEncoder()
df["Education_Level"] = le.fit_transform(df["Education_Level"])
df["Loan_Approved"] = le.fit_transform(df["Loan_Approved"])





df.head()


cols = ["Employment_Status","Marital_Status","Loan_Purpose","Property_Area","Gender","Employer_Category"]
one = OneHotEncoder(drop ="first",sparse_output=False,handle_unknown="ignore")
encoded = one.fit_transform(df[cols])
encoded_df = pd.DataFrame(encoded,columns=one.get_feature_names_out(cols),index= df.index)

df = pd.concat([df.drop(columns=cols),encoded_df],axis=1)


df.head()
#df.info()





num_cols = df.select_dtypes(include="number")
corr_matrix = num_cols.corr()

plt.figure(figsize=(15,18))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="coolwarm"
)


num_cols.corr()["Loan_Approved"].sort_values(ascending=False)





X = df.drop("Loan_Approved",axis=1)
y = df["Loan_Approved"]


X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)


from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


X_train_scaled





# Logistic regression

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

log_model = LogisticRegression()
log_model.fit(X_train_scaled,y_train)

y_pred = log_model.predict(X_test_scaled)

# Evaluation 
print("Logistic Regression Model")
print("Precision: ",precision_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,y_pred))
print("F1 Score: ",f1_score(y_test,y_pred))
print("Accuracy: ",accuracy_score(y_test,y_pred))
print("CM: ",confusion_matrix(y_test,y_pred))


# KNN classifier

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled,y_train)

y_pred = knn_model.predict(X_test_scaled)

# Evaluation 
print("knn_model Model")
print("Precision: ",precision_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,y_pred))
print("F1 Score: ",f1_score(y_test,y_pred))
print("Accuracy: ",accuracy_score(y_test,y_pred))
print("CM: ",confusion_matrix(y_test,y_pred))


# Naive Bayes

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score

nb_model = GaussianNB()
nb_model.fit(X_train_scaled,y_train)

y_pred = nb_model.predict(X_test_scaled)

# Evaluation 
print("Naive Bayes Model")
print("Precision: ",precision_score(y_test,y_pred))
print("Recall: ",recall_score(y_test,y_pred))
print("F1 Score: ",f1_score(y_test,y_pred))
print("Accuracy: ",accuracy_score(y_test,y_pred))
print("CM: ",confusion_matrix(y_test,y_pred))









